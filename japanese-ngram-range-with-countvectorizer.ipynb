{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4aa7248-77ac-481b-9606-93699a6ef6fa",
   "metadata": {},
   "source": [
    "# はじめに\n",
    "機械学習を用いる場合、様々なライブラリやフレームワークを使いますが、日本語の文書を対象にする場合は少し注意が必要なことがあります。\n",
    "\n",
    "今回、日本語の文書を対象に、scikit-learn (0.24.2)のCountVectorizerを用いてベクトル化する時の、analyzerオプションとtokenizerオプションの違いについてまとめます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f195c3c4-a5cf-46b3-ac0c-b72cfe051963",
   "metadata": {},
   "source": [
    "## 英語の文書の場合\n",
    "CountVectorizerは、単語が空白文字で区切られる文書を想定しています。そのため、日本語の文書をデフォルトの設定で分かち書きしようとすると、うまくいきません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f5ba277-65b0-4cef-af47-2ce535fdea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# コーパス\n",
    "# 文は Japan Times より。\n",
    "all_sents=['The top court on Wednesday again ruled that legal provisions forcing married couples to use the same surname are constitutional, upholding a Supreme Court judgment from 2015.',\n",
    "            'Japan is suspending approval for companies to inoculate staff amid concerns that an increase in such applications will hamper the smooth delivery of shots, Taro Kono, the minister in charge of vaccines, said Wednesday.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0cb8d75c-1540-41dd-982f-763dae44f24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2015', 'again', 'amid', 'an', 'applications', 'approval', 'are', 'charge', 'companies', 'concerns', 'constitutional', 'couples', 'court', 'delivery', 'for', 'forcing', 'from', 'hamper', 'in', 'increase', 'inoculate', 'is', 'japan', 'judgment', 'kono', 'legal', 'married', 'minister', 'of', 'on', 'provisions', 'ruled', 'said', 'same', 'shots', 'smooth', 'staff', 'such', 'supreme', 'surname', 'suspending', 'taro', 'that', 'the', 'to', 'top', 'upholding', 'use', 'vaccines', 'wednesday', 'will']\n"
     ]
    }
   ],
   "source": [
    "# まずは英語の単語(1-gram) \n",
    "# analyzer に'word'を指定(デフォルト)\n",
    "\n",
    "cv = CountVectorizer()\n",
    "counts = cv.fit_transform(all_sents)\n",
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5ed9c96-9328-46de-a352-d005646dc161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['again ruled', 'amid concerns', 'an increase', 'applications will', 'approval for', 'are constitutional', 'charge of', 'companies to', 'concerns that', 'constitutional upholding', 'couples to', 'court judgment', 'court on', 'delivery of', 'for companies', 'forcing married', 'from 2015', 'hamper the', 'in charge', 'in such', 'increase in', 'inoculate staff', 'is suspending', 'japan is', 'judgment from', 'kono the', 'legal provisions', 'married couples', 'minister in', 'of shots', 'of vaccines', 'on wednesday', 'provisions forcing', 'ruled that', 'said wednesday', 'same surname', 'shots taro', 'smooth delivery', 'staff amid', 'such applications', 'supreme court', 'surname are', 'suspending approval', 'taro kono', 'that an', 'that legal', 'the minister', 'the same', 'the smooth', 'the top', 'to inoculate', 'to use', 'top court', 'upholding supreme', 'use the', 'vaccines said', 'wednesday again', 'will hamper']\n"
     ]
    }
   ],
   "source": [
    "# 英語の 2-gram \n",
    "cv = CountVectorizer(ngram_range=(2, 2)) # (1, 2)とすると 1-gram と 2-gram の和集合 \n",
    "counts = cv.fit_transform(all_sents)\n",
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d862f9-8c00-4624-93b9-c5df011a542a",
   "metadata": {},
   "source": [
    "## 日本語の文書の場合\n",
    "日本語の文書をデフォルトの設定で分かち書きしようとすると、うまくいきません。tokenizerオプションに分かち書きをする関数を渡しますが、analyzerに渡してもうまくいきます。ネットで探すとanalyzerに渡した例のほうが多いように思います。\n",
    "\n",
    "1-gramの場合はどちらのオプションにしても問題ありませんが、ngram_rangeを使ってn-gramを使いたい場合は、分かち書きの関数はtokenizerに渡す必要があります。\n",
    "\n",
    "これは、[CountVectorizerのマニュアル](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)のngram_rangeのところに、以下のように書いてある通り、ngram_rangeを有効にするにはanalyzerには関数は渡せないからです。\n",
    "> Only applies if analyzer is not callable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a628c0f-588a-4bf2-b83a-72eb3435763a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日本語のコーパス\n",
    "# 文は読売オンラインより\n",
    "all_sents = ['東京五輪・パラリンピック大会組織委員会は２３日、販売済みのチケットの一部について再抽選を実施すると発表した。',\n",
    "            '　河野行政・規制改革相がテレビ番組に連日出演し、若者に新型コロナウイルスワクチンの接種を呼びかけている。']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bae93f57-6214-4a0f-8999-a5e1712935f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['東京', '五輪', 'パラリンピック', '大会', '組織', '委員', '会', '２', '３', '日', '販売', '済み', 'チケット', '一部', '抽選', '実施', '発表']\n",
      "['河野', '行政', '規制', '改革', '相', 'テレビ', '番組', '連日', '出演', '若者', '新型', 'コロナウイルスワクチン', '接種']\n"
     ]
    }
   ],
   "source": [
    "# 分かち書きをする関数を定義\n",
    "import MeCab\n",
    "\n",
    "tagger = MeCab.Tagger('-Owakati')\n",
    "tagger.parse('')\n",
    "\n",
    "def sent2words(sent):\n",
    "  node = tagger.parseToNode(sent)\n",
    "\n",
    "  word_list = []\n",
    "  while node:\n",
    "    meta = node.feature.split(',')\n",
    "    if meta[0] == '名詞':\n",
    "        word_list.append(node.surface)\n",
    "    node = node.next\n",
    "\n",
    "  return(word_list)\n",
    "\n",
    "# テスト\n",
    "for i in all_sents:\n",
    "    print(sent2words(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95e4d84b-e01a-4384-863e-a218b2efac36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['パラリンピック大会組織委員会は２３日', '東京五輪', '河野行政', '若者に新型コロナウイルスワクチンの接種を呼びかけている', '規制改革相がテレビ番組に連日出演し', '販売済みのチケットの一部について再抽選を実施すると発表した']\n"
     ]
    }
   ],
   "source": [
    "# デフォルトの設定ではうまく単語に分割できない。\n",
    "cv = CountVectorizer()\n",
    "counts = cv.fit_transform(all_sents)\n",
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7de93c1-6829-4c5e-81dd-36234aae0521",
   "metadata": {},
   "source": [
    "### analyzerに関数を渡す\n",
    "日本語文書で1-gramを使う場合、analyzerに分かち書きの関数を渡せばよいです。ただし、以下で見るように、n-gramを使う場合、このやり方ははうまくいきません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "712ea753-5fb5-4ba6-9624-e9e6f0a74fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['コロナウイルスワクチン', 'チケット', 'テレビ', 'パラリンピック', '一部', '五輪', '会', '出演', '大会', '委員', '実施', '抽選', '接種', '改革', '新型', '日', '東京', '河野', '済み', '番組', '発表', '相', '組織', '若者', '行政', '規制', '販売', '連日', '２', '３']\n"
     ]
    }
   ],
   "source": [
    "# analyzer に分かち書きの関数を指定\n",
    "cv = CountVectorizer(analyzer=sent2words)\n",
    "counts = cv.fit_transform(all_sents)\n",
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3f1489b-6ddb-4ede-8145-a2c80462bbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['コロナウイルスワクチン', 'チケット', 'テレビ', 'パラリンピック', '一部', '五輪', '会', '出演', '大会', '委員', '実施', '抽選', '接種', '改革', '新型', '日', '東京', '河野', '済み', '番組', '発表', '相', '組織', '若者', '行政', '規制', '販売', '連日', '２', '３']\n"
     ]
    }
   ],
   "source": [
    "# analyzer に関数を指定した上で ngram_range を指定\n",
    "cv = CountVectorizer(analyzer=sent2words, ngram_range=(1, 2))\n",
    "counts = cv.fit_transform(all_sents)\n",
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26587c2-1ed0-4b64-9189-43ea31f50dfd",
   "metadata": {},
   "source": [
    "### tokenizerに関数を渡す\n",
    "ngram_rangeを使う場合は、分かち書きの関数はanalyzerではなくtokenizerに渡す必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "851f4ca3-d3ae-4400-b29a-f4475a7597d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['コロナウイルスワクチン', 'チケット', 'テレビ', 'パラリンピック', '一部', '五輪', '会', '出演', '大会', '委員', '実施', '抽選', '接種', '改革', '新型', '日', '東京', '河野', '済み', '番組', '発表', '相', '組織', '若者', '行政', '規制', '販売', '連日', '２', '３']\n"
     ]
    }
   ],
   "source": [
    "# tokenizer に分かち書きの関数を指定\n",
    "cv = CountVectorizer(tokenizer=sent2words)\n",
    "counts = cv.fit_transform(all_sents)\n",
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36577478-8d07-4006-865a-d9b68b3c740f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['コロナウイルスワクチン', 'コロナウイルスワクチン 接種', 'チケット', 'チケット 一部', 'テレビ', 'テレビ 番組', 'パラリンピック', 'パラリンピック 大会', '一部', '一部 抽選', '五輪', '五輪 パラリンピック', '会', '会 ２', '出演', '出演 若者', '大会', '大会 組織', '委員', '委員 会', '実施', '実施 発表', '抽選', '抽選 実施', '接種', '改革', '改革 相', '新型', '新型 コロナウイルスワクチン', '日', '日 販売', '東京', '東京 五輪', '河野', '河野 行政', '済み', '済み チケット', '番組', '番組 連日', '発表', '相', '相 テレビ', '組織', '組織 委員', '若者', '若者 新型', '行政', '行政 規制', '規制', '規制 改革', '販売', '販売 済み', '連日', '連日 出演', '２', '２ ３', '３', '３ 日']\n"
     ]
    }
   ],
   "source": [
    "# tokenizer に関数を指定した上で ngram_range を指定\n",
    "cv = CountVectorizer(tokenizer=sent2words, ngram_range=(1, 2))\n",
    "counts = cv.fit_transform(all_sents)\n",
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea76160-c4eb-48e9-ae89-3a021c740d80",
   "metadata": {},
   "source": [
    "### まとめ\n",
    "最後のセルでは、(1, 2)-gramに分けたので、1つの単語のみと、二つの単語が空白で連結されたものが\n",
    "出力されることが分かります。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
